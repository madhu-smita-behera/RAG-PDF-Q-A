# -*- coding: utf-8 -*-
"""RAG_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wHjqIvr7-hucVfg5EaFZY7EtxID2Cm5Z

## Step 1: Install the required libraries
- LANGCHAIN: an open source framework for building applications based on LLM (Large Language Models)
- FAISS: Facebook AI Similarity Search allows to quickly search for embeddings of multimedia documents that are similar to each other.
- SENTENCE TRANSFORMERS: used to create dense vector representations (embeddings) of sentences, paragraphs, images.
- HUGGINGFACE HUB: a platform for the machine learning community to share and collaborate on models, datasets, and applications.
- GRADIO: used to create interactive web interfaces for machine learning models, APIs, and any python functions.
- PYPDF: a free and open source python pdf library capable of splitting, merging, cropping, and transforming PDF files.
"""

import os
import gradio as gr
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.llms import HuggingFacePipeline  # âœ… CHANGED HERE
from langchain.chains import RetrievalQA
from transformers import pipeline

# Load Hugging Face Token from environment (if needed)
HUGGINGFACEHUB_API_TOKEN = os.getenv("HUGGINGFACEHUB_API_TOKEN")

# 1. Function to load and process the PDF
def process_pdf(file):
    try:
        # Load PDF using PyPDFLoader
        loader = PyPDFLoader(file.name)
        documents = loader.load()
        print("Loaded PDF documents:", len(documents))  # Debug: Check if PDF is loaded

        # Split the document into chunks
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        docs = text_splitter.split_documents(documents)
        print("Total chunks:", len(docs))  # Debug: Check if text is split into chunks

        # Embed the documents
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        vectorstore = FAISS.from_documents(docs, embeddings)
        print("Vectorstore created successfully!")  # Debug: Check if vectorstore is created

        return vectorstore
    except Exception as e:
        print("Error in processing PDF:", e)
        return None

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# Load a general text-generation or seq2seq model
model_name = "google/flan-t5-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

from transformers import pipeline
text_gen_pipeline = pipeline(
    "text2text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=120,   # ðŸ‘‰ allows longer answers
    min_new_tokens=80,   # ðŸ‘‰ ensures answers are not too short
    temperature=0.3       # ðŸ‘‰ makes it a bit more deterministic
)


from langchain.llms import HuggingFacePipeline
llm = HuggingFacePipeline(pipeline=text_gen_pipeline)


# 3. Define the QA function using Langchain (retrieval augmented generation)
def answer_question(query, pdf_file):
    # Process the uploaded PDF and create the vector store
    vectorstore = process_pdf(pdf_file)
    if vectorstore is None:
        return "Failed to process the PDF. Please check the file and try again."

    # Perform retrieval
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})


    # Initialize the QA chain
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,  # âœ… use wrapped model
        chain_type="stuff",
        retriever=retriever
    )

    # Get the answer from the model
    result = qa_chain.run(query)

    return result

# 4. Gradio Interface for File Upload and Question Input
iface = gr.Interface(
    fn=answer_question,
    inputs=[
        gr.Textbox(lines=2, placeholder="Ask a question..."),
        gr.File(label="Upload PDF")  # Allow user to upload a PDF file
    ],
    outputs="text",
    title="ðŸ“„ PDF Question Answering",
    description="Ask any question from the uploaded PDF!"
)

iface.launch(share=True)

